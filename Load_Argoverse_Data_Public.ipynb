{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "val_path = \"./new_val_in/new_val_in\" \n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    out = torch.LongTensor(out)\n",
    "    inp = torch.tensor(inp, dtype=torch.float)\n",
    "    out = torch.tensor(out, dtype=torch.float)\n",
    "    return [inp, out]\n",
    "\n",
    "# sampler = RandomSampler(train_dataset, num_samples = 1000, replacement=True)\n",
    "sampler = RandomSampler(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, sampler = sampler, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "#     print(batch)\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.tensor(inp, dtype=torch.float)\n",
    "    agent = [scene['agent_id'] for scene in batch]\n",
    "    track = [scene['track_id'] for scene in batch]\n",
    "    print(np.shape(agent))\n",
    "#     print(track)\n",
    "    return [inp, agent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_test_collate, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch, agent_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.9620e+03,  1.4230e+03,  2.0000e+00,  2.0000e+00],\n",
       "          [ 2.9620e+03,  1.4230e+03,  2.0000e+00,  3.0000e+00],\n",
       "          [ 2.9620e+03,  1.4240e+03,  2.0000e+00,  3.0000e+00],\n",
       "          ...,\n",
       "          [ 2.9620e+03,  1.4380e+03, -3.0000e+00,  6.0000e+00],\n",
       "          [ 2.9620e+03,  1.4390e+03, -4.0000e+00,  7.0000e+00],\n",
       "          [ 2.9610e+03,  1.4400e+03, -4.0000e+00,  6.0000e+00]],\n",
       "\n",
       "         [[ 2.9610e+03,  1.4480e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.9610e+03,  1.4480e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.9610e+03,  1.4470e+03,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 2.9610e+03,  1.4470e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.9610e+03,  1.4470e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.9610e+03,  1.4480e+03,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 2.9770e+03,  1.4440e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.9770e+03,  1.4440e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.9770e+03,  1.4440e+03,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 2.9750e+03,  1.4450e+03, -4.3000e+01, -6.0000e+00],\n",
       "          [ 2.9770e+03,  1.4450e+03,  1.8000e+01,  5.0000e+00],\n",
       "          [ 2.9770e+03,  1.4450e+03,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 6.5800e+02,  1.9960e+03,  0.0000e+00,  4.0000e+00],\n",
       "          [ 6.5800e+02,  1.9960e+03,  0.0000e+00,  4.0000e+00],\n",
       "          [ 6.5800e+02,  1.9970e+03,  0.0000e+00,  4.0000e+00],\n",
       "          ...,\n",
       "          [ 6.5800e+02,  2.0080e+03,  0.0000e+00,  3.0000e+00],\n",
       "          [ 6.5800e+02,  2.0080e+03,  0.0000e+00,  4.0000e+00],\n",
       "          [ 6.5800e+02,  2.0090e+03,  0.0000e+00,  4.0000e+00]],\n",
       "\n",
       "         [[ 6.6800e+02,  1.9770e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.6800e+02,  1.9770e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.6700e+02,  1.9770e+03, -5.0000e+00,  1.0000e+00],\n",
       "          ...,\n",
       "          [ 6.6300e+02,  1.9760e+03, -1.0000e+00,  0.0000e+00],\n",
       "          [ 6.6200e+02,  1.9770e+03, -9.0000e+00,  3.0000e+00],\n",
       "          [ 6.6200e+02,  1.9770e+03,  0.0000e+00, -1.0000e+00]],\n",
       "\n",
       "         [[ 6.8400e+02,  1.9700e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.8400e+02,  1.9700e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.8400e+02,  1.9700e+03, -1.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 6.8300e+02,  1.9700e+03, -1.0000e+00,  0.0000e+00],\n",
       "          [ 6.8300e+02,  1.9700e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.8200e+02,  1.9700e+03, -2.0000e+00, -1.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 7.3900e+02,  1.8640e+03,  0.0000e+00, -1.1000e+01],\n",
       "          [ 7.3900e+02,  1.8620e+03,  0.0000e+00, -1.0000e+01],\n",
       "          [ 7.3900e+02,  1.8610e+03,  0.0000e+00, -1.0000e+01],\n",
       "          ...,\n",
       "          [ 7.3800e+02,  1.8380e+03,  0.0000e+00, -8.0000e+00],\n",
       "          [ 7.3800e+02,  1.8370e+03,  0.0000e+00, -8.0000e+00],\n",
       "          [ 7.3800e+02,  1.8370e+03,  0.0000e+00, -6.0000e+00]],\n",
       "\n",
       "         [[ 7.4100e+02,  1.8870e+03,  0.0000e+00, -1.3000e+01],\n",
       "          [ 7.4000e+02,  1.8860e+03, -1.0000e+00, -9.0000e+00],\n",
       "          [ 7.4000e+02,  1.8850e+03,  0.0000e+00, -7.0000e+00],\n",
       "          ...,\n",
       "          [ 7.3900e+02,  1.8590e+03,  0.0000e+00, -6.0000e+00],\n",
       "          [ 7.3900e+02,  1.8580e+03,  0.0000e+00, -1.5000e+01],\n",
       "          [ 7.3900e+02,  1.8570e+03,  0.0000e+00, -5.0000e+00]],\n",
       "\n",
       "         [[ 7.4500e+02,  1.9120e+03, -1.0000e+00, -7.0000e+00],\n",
       "          [ 7.4500e+02,  1.9100e+03,  0.0000e+00, -1.6000e+01],\n",
       "          [ 7.4500e+02,  1.9100e+03,  0.0000e+00, -7.0000e+00],\n",
       "          ...,\n",
       "          [ 7.4300e+02,  1.8800e+03,  0.0000e+00, -9.0000e+00],\n",
       "          [ 7.4300e+02,  1.8780e+03,  0.0000e+00, -1.8000e+01],\n",
       "          [ 7.4300e+02,  1.8770e+03,  0.0000e+00, -9.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 2.8430e+03,  1.3210e+03, -4.0000e+00, -4.0000e+00],\n",
       "          [ 2.8430e+03,  1.3210e+03, -4.0000e+00, -4.0000e+00],\n",
       "          [ 2.8420e+03,  1.3210e+03, -4.0000e+00, -3.0000e+00],\n",
       "          ...,\n",
       "          [ 2.8300e+03,  1.3100e+03, -5.0000e+00, -5.0000e+00],\n",
       "          [ 2.8290e+03,  1.3090e+03, -5.0000e+00, -5.0000e+00],\n",
       "          [ 2.8290e+03,  1.3090e+03, -6.0000e+00, -5.0000e+00]],\n",
       "\n",
       "         [[ 2.8470e+03,  1.3210e+03, -4.0000e+00, -3.0000e+00],\n",
       "          [ 2.8460e+03,  1.3210e+03, -4.0000e+00, -3.0000e+00],\n",
       "          [ 2.8460e+03,  1.3200e+03, -4.0000e+00, -4.0000e+00],\n",
       "          ...,\n",
       "          [ 2.8310e+03,  1.3070e+03, -6.0000e+00, -5.0000e+00],\n",
       "          [ 2.8300e+03,  1.3060e+03, -6.0000e+00, -6.0000e+00],\n",
       "          [ 2.8300e+03,  1.3060e+03, -6.0000e+00, -5.0000e+00]],\n",
       "\n",
       "         [[ 2.8570e+03,  1.3300e+03, -4.0000e+00, -3.0000e+00],\n",
       "          [ 2.8570e+03,  1.3300e+03, -4.0000e+00, -3.0000e+00],\n",
       "          [ 2.8560e+03,  1.3300e+03, -3.0000e+00, -3.0000e+00],\n",
       "          ...,\n",
       "          [ 2.8420e+03,  1.3160e+03, -7.0000e+00, -6.0000e+00],\n",
       "          [ 2.8410e+03,  1.3160e+03, -6.0000e+00, -6.0000e+00],\n",
       "          [ 2.8400e+03,  1.3150e+03, -7.0000e+00, -7.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "#         out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(iterator):\n",
    "        data, target = torch.reshape(data, (4, 60, -1)).to(device), torch.reshape(target[:,:,:,:2], (4, 60, -1)).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         break\n",
    "        loss = nn.MSELoss()(output, target)\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, agent in test_loader:\n",
    "            data, agent = torch.reshape(data, (4, 60, -1)).to(device)\n",
    "            output = model(data)\n",
    "#             print(output)\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dimension\n",
    "input_dim = 76\n",
    "hidden_dim = 60  # hidden layer dimension\n",
    "layer_dim = 1   # number of hidden layers\n",
    "output_dim = 60   # output dimension\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"  \n",
    "    \n",
    "learning_rate = 0.0001\n",
    "momentum = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = NN(input_dim, output_dim, hidden_dim, layer_dim)\n",
    "# model = net.to(device) #using cpu here\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "#                       momentum=momentum, weight_decay=1e-5)\n",
    "# num_epoch = 10\n",
    "\n",
    "# for epoch in range(1, num_epoch + 1):\n",
    "#         train(model, device, train_loader, optimizer, epoch)\n",
    "#         torch.save(model.state_dict(), 'checkpoints/train-epoch{}.pth'.format(epoch + 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(\"checkpoints/train-epoch3.pth\",map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "#     print(batch)\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.tensor(inp, dtype=torch.float)\n",
    "    agent = [scene['agent_id'] for scene in batch]\n",
    "    track = [scene['track_id'] for scene in batch]\n",
    "    track_ids = []\n",
    "    for scene in range(len(agent)):\n",
    "        for track_id in range(len(track[scene])):\n",
    "            if agent[scene] == track[scene][track_id][0][0]:\n",
    "                track_ids.append(track_id)\n",
    "                break\n",
    "    return [inp, track_ids]\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_test_collate, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, agent in test_loader:\n",
    "            data = torch.reshape(data, (4, 60, -1)).to(device)\n",
    "            output = torch.reshape(model(data), (4, 60, 30, -1))\n",
    "            for i in range(len(agent)):\n",
    "                scene = output[i][agent[i]]\n",
    "                predictions.append(scene)\n",
    "    return predictions\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NN(input_dim, output_dim, hidden_dim, layer_dim)\n",
    "net.load_state_dict(torch.load(\"checkpoints/train-epoch3.pth\",map_location='cpu'))\n",
    "model = net.to(device)\n",
    "preds = test(model, device, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = [torch.reshape(t, (-1,)) for t in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     net = NN(input_dim, output_dim, hidden_dim, layer_dim)\n",
    "#     net.load_state_dict(torch.load(\"checkpoints/train-epoch3.pth\",map_location='cpu'))\n",
    "#     net.eval()\n",
    "    \n",
    "#     output = net(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = sample.set_index('ID')\n",
    "for i in range(3200):\n",
    "    preds_df.iloc[i] = predict[i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv('test_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
