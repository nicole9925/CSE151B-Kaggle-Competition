{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "val_path = \"./new_val_in/new_val_in\" \n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    out = torch.LongTensor(out)\n",
    "    inp = torch.tensor(inp, dtype=torch.float)\n",
    "    out = torch.tensor(out, dtype=torch.float)\n",
    "    return [inp, out]\n",
    "\n",
    "# sampler = RandomSampler(train_dataset, num_samples = 1000, replacement=True)\n",
    "sampler = RandomSampler(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, sampler = sampler, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "#     print(batch)\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.tensor(inp, dtype=torch.float)\n",
    "    agent = [scene['agent_id'] for scene in batch]\n",
    "    track = [scene['track_id'] for scene in batch]\n",
    "    print(np.shape(agent))\n",
    "#     print(track)\n",
    "    return [inp, agent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_test_collate, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch, agent_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 4.6060e+03,  2.3730e+03, -8.0000e+00, -2.0000e+00],\n",
       "          [ 4.6060e+03,  2.3730e+03, -8.0000e+00, -2.0000e+00],\n",
       "          [ 4.6050e+03,  2.3730e+03, -8.0000e+00, -1.0000e+00],\n",
       "          ...,\n",
       "          [ 4.5810e+03,  2.3670e+03, -1.1000e+01, -2.0000e+00],\n",
       "          [ 4.5790e+03,  2.3670e+03, -1.1000e+01, -2.0000e+00],\n",
       "          [ 4.5780e+03,  2.3660e+03, -1.1000e+01, -2.0000e+00]],\n",
       "\n",
       "         [[ 4.6240e+03,  2.3770e+03, -7.0000e+00, -1.0000e+00],\n",
       "          [ 4.6230e+03,  2.3770e+03, -8.0000e+00, -2.0000e+00],\n",
       "          [ 4.6220e+03,  2.3760e+03, -7.0000e+00, -1.0000e+00],\n",
       "          ...,\n",
       "          [ 4.6000e+03,  2.3710e+03, -9.0000e+00, -2.0000e+00],\n",
       "          [ 4.6000e+03,  2.3710e+03, -6.0000e+00, -1.0000e+00],\n",
       "          [ 4.5990e+03,  2.3710e+03, -1.0000e+01, -2.0000e+00]],\n",
       "\n",
       "         [[ 4.6570e+03,  2.3880e+03,  0.0000e+00,  1.0000e+00],\n",
       "          [ 4.6570e+03,  2.3880e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 4.6570e+03,  2.3880e+03,  0.0000e+00,  1.0000e+00],\n",
       "          ...,\n",
       "          [ 4.6570e+03,  2.3880e+03,  0.0000e+00, -1.0000e+00],\n",
       "          [ 4.6570e+03,  2.3880e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 4.6570e+03,  2.3880e+03,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 2.2310e+03,  7.7100e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2310e+03,  7.7100e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2310e+03,  7.7100e+02,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 2.2310e+03,  7.7100e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2310e+03,  7.7100e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2310e+03,  7.7100e+02,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 2.2210e+03,  7.6400e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2210e+03,  7.6400e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2210e+03,  7.6400e+02,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 2.2210e+03,  7.6400e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2210e+03,  7.6400e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2210e+03,  7.6400e+02,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 2.2390e+03,  7.7800e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2390e+03,  7.7800e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2390e+03,  7.7800e+02,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 2.2390e+03,  7.7800e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2390e+03,  7.7800e+02,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.2390e+03,  7.7800e+02,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 4.6810e+03,  2.4250e+03,  1.0000e+00, -4.0000e+00],\n",
       "          [ 4.6810e+03,  2.4240e+03,  1.0000e+00, -6.0000e+00],\n",
       "          [ 4.6810e+03,  2.4240e+03,  1.0000e+00, -6.0000e+00],\n",
       "          ...,\n",
       "          [ 4.6850e+03,  2.4080e+03,  1.0000e+00, -6.0000e+00],\n",
       "          [ 4.6860e+03,  2.4070e+03,  1.0000e+00, -5.0000e+00],\n",
       "          [ 4.6860e+03,  2.4060e+03,  1.0000e+00, -5.0000e+00]],\n",
       "\n",
       "         [[ 4.6760e+03,  2.4460e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 4.6760e+03,  2.4460e+03,  0.0000e+00, -4.0000e+00],\n",
       "          [ 4.6760e+03,  2.4450e+03,  1.0000e+00, -8.0000e+00],\n",
       "          ...,\n",
       "          [ 4.6790e+03,  2.4310e+03,  1.0000e+00, -3.0000e+00],\n",
       "          [ 4.6790e+03,  2.4300e+03,  1.0000e+00, -9.0000e+00],\n",
       "          [ 4.6800e+03,  2.4300e+03,  1.0000e+00, -6.0000e+00]],\n",
       "\n",
       "         [[ 4.6750e+03,  2.4620e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 4.6750e+03,  2.4620e+03, -1.0000e+00,  5.0000e+00],\n",
       "          [ 4.6750e+03,  2.4630e+03,  0.0000e+00,  1.3000e+01],\n",
       "          ...,\n",
       "          [ 4.6710e+03,  2.4800e+03,  0.0000e+00,  1.8000e+01],\n",
       "          [ 4.6710e+03,  2.4800e+03, -2.0000e+00,  5.0000e+00],\n",
       "          [ 4.6710e+03,  2.4810e+03, -1.0000e+00,  6.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 6.6700e+02,  3.2950e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.6700e+02,  3.2950e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.6700e+02,  3.2950e+03,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 6.6700e+02,  3.2950e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.6700e+02,  3.2950e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.6700e+02,  3.2950e+03,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 6.7700e+02,  3.2950e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.7700e+02,  3.2950e+03, -1.0000e+00, -1.0000e+00],\n",
       "          [ 6.7700e+02,  3.2950e+03,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 6.7700e+02,  3.2950e+03, -1.0000e+00,  0.0000e+00],\n",
       "          [ 6.7700e+02,  3.2950e+03,  1.0000e+00,  0.0000e+00],\n",
       "          [ 6.7700e+02,  3.2950e+03, -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "         [[ 6.8300e+02,  3.2960e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.8300e+02,  3.2960e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.8300e+02,  3.2960e+03,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 6.8300e+02,  3.2960e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.8300e+02,  3.2960e+03,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.8300e+02,  3.2960e+03,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "#         out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(iterator):\n",
    "        data, target = torch.reshape(data, (4, 60, -1)).to(device), torch.reshape(target[:,:,:,:2], (4, 60, -1)).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         break\n",
    "        loss = nn.MSELoss()(output, target)\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, agent in test_loader:\n",
    "            data, agent = torch.reshape(data, (4, 60, -1)).to(device)\n",
    "            output = model(data)\n",
    "#             print(output)\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dimension\n",
    "input_dim = 76\n",
    "hidden_dim = 60  # hidden layer dimension\n",
    "layer_dim = 1   # number of hidden layers\n",
    "output_dim = 60   # output dimension\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"  \n",
    "    \n",
    "learning_rate = 0.0001\n",
    "momentum = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = NN(input_dim, output_dim, hidden_dim, layer_dim)\n",
    "# model = net.to(device) #using cpu here\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "#                       momentum=momentum, weight_decay=1e-5)\n",
    "# num_epoch = 10\n",
    "\n",
    "# for epoch in range(1, num_epoch + 1):\n",
    "#         train(model, device, train_loader, optimizer, epoch)\n",
    "#         torch.save(model.state_dict(), 'checkpoints/train-epoch{}.pth'.format(epoch + 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(\"checkpoints/train-epoch11.pth\",map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "#     print(batch)\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.tensor(inp, dtype=torch.float)\n",
    "    agent = [scene['agent_id'] for scene in batch]\n",
    "    track = [scene['track_id'] for scene in batch]\n",
    "    track_ids = []\n",
    "    for scene in range(len(agent)):\n",
    "        for track_id in range(len(track[scene])):\n",
    "            if agent[scene] == track[scene][track_id][0][0]:\n",
    "                track_ids.append(track_id)\n",
    "                break\n",
    "    return [inp, track_ids]\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_test_collate, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, agent in test_loader:\n",
    "            data = torch.reshape(data, (4, 60, -1)).to(device)\n",
    "            output = torch.reshape(model(data), (4, 60, 30, -1))\n",
    "            for i in range(len(agent)):\n",
    "                scene = output[i][agent[i]]\n",
    "                predictions.append(scene)\n",
    "    predict = [torch.reshape(t, (-1,)) for t in predictions]\n",
    "    sample = pd.read_csv('sample_submission.csv')\n",
    "    preds_df = sample.set_index('ID')\n",
    "    for i in range(3200):\n",
    "        preds_df.iloc[i] = predict[i].tolist()\n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NN(input_dim, output_dim, hidden_dim, layer_dim)\n",
    "net.load_state_dict(torch.load(\"checkpoints/train-epoch11.pth\",map_location='cpu'))\n",
    "model = net.to(device)\n",
    "preds = predict(model, device, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('test_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.7.1+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (735.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 735.4 MB 21 kB/s  eta 0:00:012MB 27.1 MB/s eta 0:00:27                       | 52.0 MB 27.1 MB/s eta 0:00:26                       | 62.4 MB 27.1 MB/s eta 0:00:25 MB 63.5 MB/s eta 0:00:11          | 133.7 MB 62.0 MB/s eta 0:00:10                | 146.1 MB 62.0 MB/s eta 0:00:10                | 155.6 MB 62.0 MB/s eta 0:00:10MB 62.0 MB/s eta 0:00:10MB 62.4 MB/s eta 0:00:09MB 62.4 MB/s eta 0:00:09MB 46.0 MB/s eta 0:00:12     |█████████▍                      | 215.9 MB 46.0 MB/s eta 0:00:12��███▋                      | 221.6 MB 46.0 MB/s eta 0:00:12     |█████████▊                      | 223.8 MB 46.0 MB/s eta 0:00:129 MB/s eta 0:00:07█▍                    | 260.7 MB 77.9 MB/s eta 0:00:07██                    | 276.4 MB 77.9 MB/s eta 0:00:06     |████████████████                | 368.4 MB 73.8 MB/s eta 0:00:05MB/s eta 0:00:05�▏            | 440.8 MB 73.3 MB/s eta 0:00:05█████████████▏          | 485.7 MB 67.4 MB/s eta 0:00:04 eta 0:00:04        | 520.6 MB 67.4 MB/s eta 0:00:04██████████████████████▏       | 554.6 MB 29.1 MB/s eta 0:00:07██████████████████████▉       | 571.4 MB 24.2 MB/s eta 0:00:07     |█████████████████████████▌      | 585.2 MB 24.2 MB/s eta 0:00:07MB/s eta 0:00:06MB/s eta 0:00:06MB/s eta 0:00:09\n",
      "\u001b[?25hCollecting torchvision==0.8.2+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.2%2Bcu101-cp37-cp37m-linux_x86_64.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 17.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.7.1+cu101) (3.7.4.2)\n",
      "Requirement already satisfied: numpy in /home/nml015/.local/lib/python3.7/site-packages (from torch==1.7.1+cu101) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.8.2+cu101) (6.2.2)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.0\n",
      "    Uninstalling torch-1.7.0:\n",
      "      Successfully uninstalled torch-1.7.0\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx and convert-onnx-to-caffe2 are installed in '/home/nml015/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 16] Device or resource busy: '.nfs000000000191b4a400006060'\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
