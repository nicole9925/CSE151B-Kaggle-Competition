{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "#     out = [numpy.dstack([scene['p_out']]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    inp = torch.tensor(inp, dtype=torch.float)\n",
    "    out = torch.tensor(out, dtype=torch.float)\n",
    "    return [inp, out]\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-156-b8a574584fb7>:8: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  inp = torch.LongTensor(inp)\n",
      "<ipython-input-156-b8a574584fb7>:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  out = torch.LongTensor(out)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch, agent_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "#         out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(iterator):\n",
    "        data, target = torch.reshape(data, (4, 60, -1)).to(device), torch.reshape(target[:,:,:,:2], (4, 60, -1)).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         print(output.shape)\n",
    "#         break\n",
    "        loss = nn.MSELoss()(output, target)\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-384-ce3c0e6d0533>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  iterator = tqdm(train_loader, total=int(len(train_loader)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8bc94a8b8e422abba7c6391a238b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-168-3cc807f2c76d>:8: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  inp = torch.LongTensor(inp)\n",
      "<ipython-input-168-3cc807f2c76d>:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  out = torch.LongTensor(out)\n",
      "<ipython-input-168-3cc807f2c76d>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inp = torch.tensor(inp, dtype=torch.float)\n",
      "<ipython-input-168-3cc807f2c76d>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out = torch.tensor(out, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# input dimension\n",
    "input_dim = 76\n",
    "hidden_dim = 60  # hidden layer dimension\n",
    "layer_dim = 1   # number of hidden layers\n",
    "output_dim = 60   # output dimension\n",
    "\n",
    "net = NN(input_dim, output_dim, hidden_dim, layer_dim)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.5\n",
    "device = \"cpu\"\n",
    "model = net.to(device) #using cpu here\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum, weight_decay=1e-5)\n",
    "num_epoch = 10\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
