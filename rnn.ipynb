{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "val_path = \"./new_val_in/new_val_in\" \n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    out = torch.LongTensor(out)\n",
    "    inp = torch.tensor(inp, dtype=torch.float)\n",
    "    out = torch.tensor(out, dtype=torch.float)\n",
    "    return [inp, out]\n",
    "\n",
    "# sampler = RandomSampler(train_dataset, num_samples = 1000, replacement=True)\n",
    "sampler = RandomSampler(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, sampler = sampler, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch, agent_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(NN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(iterator):\n",
    "        data, target = torch.reshape(data, (4, 60, -1)).to(device), torch.reshape(target[:,:,:,:2], (4, 60, -1)).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = nn.MSELoss()(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, agent in test_loader:\n",
    "            data, agent = torch.reshape(data, (4, 60, -1)).to(device)\n",
    "            output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dimension\n",
    "input_dim = 76\n",
    "hidden_dim = 60  # hidden layer dimension\n",
    "layer_dim = 1   # number of hidden layers\n",
    "output_dim = 60   # output dimension\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"  \n",
    "    \n",
    "learning_rate = 0.0001\n",
    "momentum = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = NN(input_dim, output_dim, hidden_dim, layer_dim)\n",
    "# model = net.to(device) #using cpu here\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "#                       momentum=momentum, weight_decay=1e-5)\n",
    "# num_epoch = 10\n",
    "\n",
    "# for epoch in range(1, num_epoch + 1):\n",
    "#         train(model, device, train_loader, optimizer, epoch)\n",
    "#         torch.save(model.state_dict(), 'checkpoints/train-epoch{}.pth'.format(epoch + 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(\"checkpoints/train-epoch11.pth\",map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "\n",
    "def my_test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "#     print(batch)\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.tensor(inp, dtype=torch.float)\n",
    "    agent = [scene['agent_id'] for scene in batch]\n",
    "    track = [scene['track_id'] for scene in batch]\n",
    "    track_ids = []\n",
    "    for scene in range(len(agent)):\n",
    "        for track_id in range(len(track[scene])):\n",
    "            if agent[scene] == track[scene][track_id][0][0]:\n",
    "                track_ids.append(track_id)\n",
    "                break\n",
    "    return [inp, track_ids]\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_test_collate, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, agent in test_loader:\n",
    "            data = torch.reshape(data, (4, 60, -1)).to(device)\n",
    "            output = torch.reshape(model(data), (4, 60, 30, -1))\n",
    "            for i in range(len(agent)):\n",
    "                scene = output[i][agent[i]]\n",
    "                predictions.append(scene)\n",
    "    predict = [torch.reshape(t, (-1,)) for t in predictions]\n",
    "    sample = pd.read_csv('sample_submission.csv')\n",
    "    preds_df = sample.set_index('ID')\n",
    "    for i in range(3200):\n",
    "        preds_df.iloc[i] = predict[i].tolist()\n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NN(input_dim, output_dim, hidden_dim, layer_dim)\n",
    "net.load_state_dict(torch.load(\"checkpoints/train-epoch11.pth\",map_location=device))\n",
    "model = net.to(device)\n",
    "preds = predict(model, device, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('test_preds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
